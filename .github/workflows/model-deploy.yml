name: Containerize Model in Inference Server
on:
  repository_dispatch:
    types: "deploy-model"
# A workflow run is made up of one or more jobs that can run sequentially or in parallel
jobs:
  build_inference_server:
    # The type of runner that the job will run on
    runs-on: ubuntu-latest
    env:
      WANDB_API_KEY: ${{ secrets.WANDB_API_KEY }}
    # Steps represent a sequence of tasks that will be executed as part of the job
    steps:
      - uses: actions/checkout@v4
      - run: 'echo "payload: ${{ toJson(github.event.client_payload) }}"'
      - name: Set up Python     
        uses: actions/setup-python@v5
        with: 
          python-version: '3.12.5'
          cache: 'pip'
      - name: Install Dependencies
        run: pip install -r ./requirements.txt
      - name: Login to W&B
        run: wandb login
      - name: Retrieve Artifacts
        run: sleep 180s
        shell: bash
      - name: Containerize the artifact in our inference server
        run: sleep 180s
        shell: bash
      #   run: python .github/workflows/retrieve_artifacts.py --registered_model_name "${{ github.event.client_payload.artifact_version_string }}"
      # - name: Containerize the artifact in our inference server
      #   uses: docker/build-push-action@v4
      #   with:
      #     context: ./docker_context
      #     file: src/torchserve/Dockerfile
      #     push: true
      #     tags: ${{ env.GAR_LOCATION }}-docker.pkg.dev/${{ env.PROJECT_ID }}/${{ env.REPOSITORY }}/${{ env.SERVICE }}:${{ github.sha }}
